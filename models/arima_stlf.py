# -*- coding: utf-8 -*-
"""ARIMA_STLF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vdjAsXzFxtSFjZO1qrG4XkQ45aPuBAUl
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error
from google.colab import drive

"""**Import Data**"""

dataset = pd.read_csv("continuous dataset.csv")
dataset.head()

"""**Data normalization and cleaning**"""

dataset['datetime'] = pd.to_datetime(dataset['datetime'])
plt.figure(figsize=(12, 6))
plt.plot(dataset['datetime'], dataset['nat_demand'], label='nat_demand')
plt.xlabel('Datetime')
plt.ylabel('Nat Demand')
plt.title('Nat Demand vs Datetime')
plt.legend()
plt.tight_layout()
plt.show()

"""MinMax scaling"""

features = [col for col in dataset.columns if col not in ['datetime','Holiday_ID']]

scaler  = MinMaxScaler()
dataset[features] = scaler.fit_transform(dataset[features])
dataset.head()

"""**Hampel identifier to fill in missing Values**              """

#function for hampel Identifier|
def hampel_filter(series, window_size=7, n_sigmas=3):
    """
    Apply Hampel filter to a Pandas Series to detect and replace outliers.

    Args:
        series (pd.Series): Time series data
        window_size (int): Size of the sliding window (must be odd)
        n_sigmas (float): Threshold in terms of scaled MAD

    Returns:
        pd.Series: Series with outliers replaced by median
    """
    n = len(series)
    new_series = series.copy()
    k = 1.4826  # scaling factor for MAD â†’ std

    for i in range(window_size, n - window_size):
        window = series[(i - window_size):(i + window_size)]
        median = window.median()
        mad = k * np.median(np.abs(window - median))

        if np.abs(series[i] - median) > n_sigmas * mad:
            new_series[i] = median  # replace outlier with median

    return new_series

columns_to_filter = [col for col in dataset.columns if col not in [  "datetime" ,"Holiday_ID","school","holiday"]]
print(columns_to_filter)

for col in columns_to_filter:
    dataset[col] = hampel_filter(dataset[col], window_size=7, n_sigmas=3)

plt.figure(figsize=(12, 6))
plt.plot(dataset['datetime'], dataset['nat_demand'], label='nat_demand')
plt.xlabel('Datetime')
plt.ylabel('Nat Demand')
plt.title('Nat Demand vs Datetime')
plt.legend()
plt.tight_layout()
plt.show()

""" **stationarity and perform differencing if necessary**





"""

# Suppose 'load' is your load demand column
# and 'df' is your dataset with datetime index
series = dataset['nat_demand']
#Train-test split
train_size = int(len(series) * 0.65)
train, test = series[:train_size], series[train_size:]

#check for stationarity for the train
result = adfuller(train)
print("ADF Statistic:", result[0])
print("p-value:", result[1])
print("Critical Values:")
for key, value in result[4].items():
    print(f"\t{key}: {value}")

# the data is stationary

train_diff = train.diff().dropna()

"""Determining ARIMA parameters"""

plot_acf(train)
plt.show()

plot_pacf(train)
plt.show()

"""### Fitting the ARIMA model"""

model = ARIMA(train , order=(0,1,0))
model_fit  = model.fit()
print(model_fit.summary())

"""# Forecasting"""

# Forecast the same length as test
forecast = model_fit.forecast(steps=len(test))

# Plot prediction vs real
plt.figure(figsize=(10,5))
plt.plot(train.index, train, label='Train')
plt.plot(test.index, test, label='Test')
plt.plot(test.index, forecast, label='Forecast', color='red')
plt.legend()
plt.show()

"""# Evalutation"""

from sklearn.metrics import mean_squared_error, mean_absolute_error

mse = mean_squared_error(test, forecast)
mae = mean_absolute_error(test, forecast)
rmse = np.sqrt(mse)

print(f'MSE: {mse}, RMSE: {rmse}, MAE: {mae}')