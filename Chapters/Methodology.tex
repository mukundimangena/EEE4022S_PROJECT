\chapter{Methodology}

The goal for this research is to investigate the impact of ML methods in STLF. As seen in the literature review ML methods have proved to better predict time series data. The main downside that has been identified within using ML methods is the processing time , however this downside is offset by the need of an accurate method of prediction. This is due to the cost of inaccurate predictions to the power providers. The literature review \ref{litReview} highlights the effectiveness of ARIMA as a statistical model in STLF and SVM's as an early AI model that is also effective in temporal prediction tasks. These two models are therefore used as the benchmarking tools to evaluate the effectiveness of advanced ML/AI models in STLF. The \ref{litReview} explains the superiority of using hybrid models to capture the benefits of different methods in one combination. Therefore in this research we will test the effectiveness of Bi-LSTM , CNN-LSTM and a DBN-RNN in STLF. We will also check the effects of data preprocessing on the final result of the model.

\section{Data Collection and Description}
The dataset that is used in the experiments handled in this research was collected by the Panama City government in central America as an initiative to research and improve  methods for short term load forecasting. The dataset is available on Kaggle and  Mendeley Data and provides historical records of electrical load data and relevant weather variables of Panama city\cite{dataset}.

The dataset consists of hourly observations spanning the period from January 2015 to December 2019, yielding approximately 48048 data points. The target variable is the load demand measured in megawatts(MW), while the other features include multiple weather and environmental parameters recorded at different stations across Santiago, Tocumen and David. 

The dataset has the following features:
\begin{itemize}
	\item datetime - The date and time sampled every hour from 
	\item T2M – Temperature at 2 meters above ground (°C)
	\item QV2M – Specific humidity at 2 meters (\%) sampled in the three cities
	\item TQL – Total cloud water content (liters/\si{m^2}) sampled n the three cities
	\item W2M – Wind speed at 2 meters (m/s) sampled in the three cities
	\item Holiday\_ID - a unique value representing a particular holiday in the country
	\item holiday - a binary value representing whether the day is a holiday or not
	\item school - a binary representing schools being open or closed \cite{dataset}
	
\end{itemize}


The environmental features in the dataset are sampled hourly in the three cities and are represented as toc, san and dav as the extensions of the feature name (e.g. T2M\_dav would be the temperature in David). These meteorological inputs have been selected due to their established influence on electricity demand, as load consumption often correlates with environmental factors such as ambient temperature, humidity, and weather patterns.The relationship between temperature and load has been established with Hor et al \cite{hor2005analyzing} seeing a correlation in the increase in temperature with the increase in the load demand.

The dataset has been cleaned previously by the  initial collectors to ensure minimum erroneous values. The dataset has 4 separate folders namely:
\begin{itemize}
	\item continuous-dataset.csv - containing data sampled every hour for the duration of the collection
	\item test\_dataframes.xslx - a test dataset prepared with historical load from 4 weeks previously \cite{dataset}
	\item train\_dataframes.xslx - a train dataset prepared with historical load from 4 weeks previously with hourly granularity \cite{dataset}
	\item weekly\_pre\_dispatch\_forecast.csv - contains the load forecast from the weekly predispatch report
\end{itemize}

To train the models in this research I chose to use the continuous\_dataset.csv. The decision to use this dataset was because of the comprehensive feature set in the dataset. This dataset also has continuous unsplit time series data allowing for testing of custom train test splits that align with my model design. Finally the flexibility for feature engineering on this dataset is enhanced. It can allow you to generate custom lagged features and rolling statistics giving the researcher transparency and reproducibility.

\section{Data Preprocessing \label{sec:datapreprocessing}}

Data preprocessing is an important step in training of ML and statistical models as it ensures that the data being used is free of noise and outliers. Preprocessing also includes feature engineering which help identify and retain the most influential features, hence simplifying models, reducing redundancy and improving performance \cite{gao2021cooling}.

\subsection{Choice of programming language}
There were two options for the programming language to use for this problem, which were Python and MATLAB. Both these choices offered pros and cons, shown in table \ref{tab:python_matlab_comparison}.
\begin{table}[h!]
	\centering
	\renewcommand{\arraystretch}{1.8} % spacing
	\begin{tabular}{|p{3.5cm}|p{5.5cm}|p{5.5cm}|}
		\hline
		\textbf{Aspect} & \textbf{Python} & \textbf{MATLAB} \\
		\hline
		\textbf{Data Processing} & Rich data processing framework(Pandas, NumPy). & Built-in data handling but less flexible than Python’s frameworks. \\
		\hline
		\textbf{Machine Learning \& AI} & Strong libraries: TensorFlow, PyTorch, Scikit-learn. & ML toolboxes available, but limited adoption compared to Python. \\
		\hline
		\textbf{Community Support} & Huge global community; extensive tutorials, forums, and open-source contributions. & Strong academic/engineering base, but smaller community outside academia. \\
		\hline
		\textbf{Flexibility of production environment} & Works well for online development online with google collab offering CPU and GPU services. & Better integration with control simulations, and hardware prototyping. \\
		\hline
		\textbf{Ease of Use} & Easy-to-read syntax, intuitive for beginners, widely taught. & Powerful for numerical computing syntax less intuitive for general-purpose tasks. \\
		\hline
		\textbf{Performance} & Fast with optimized libraries (NumPy, TensorFlow GPU acceleration). & Highly optimized for matrix operations sometimes faster out-of-the-box for linear algebra. \\
		\hline
	\end{tabular}
	\caption{Comparison of Python and MATLAB for data analysis and machine learning.}
	\label{tab:python_matlab_comparison}
\end{table}

Matlab is powerful in numerical computing and is widely used in academia and engineering settings, python was chosen for this research due to several key reasons. Python provides robust data processing frameworks, which make data cleaning, transformation and preprocessing efficient and straightforward. Python supports industry standard ML frameworks such as TensorFlow and Scikit-learn that were extensively used in this research for setting up and training the models. These models offer a ease of use and advanced modeling and experimentation. Python has a massive global community offering more resources and troubleshooting support more than MATLAB.

\subsection{Feature Engineering}
The data handling framework that is used in the project is python Pandas. Pandas offers a wide range of features to process and feature engineer your dataset. It also sets the dataset into a format that is user friendly for training and testing both statistical and machine learning models. 

\paragraph{Forward Filling}
The first step taken to ensure that the dataset is complete and there are no missing values, was the forward fill method. Forward fill is a method where you fill a missing value with the last known value. The last known value is carried forward to replace the missing value. An illustration of how this method works is shown in figure \ref{fig:forward_fill}. This method is simple and effective for filling in values such as temperature which have low variance. 

\paragraph{Day of Week Encoding}
A \texttt{day\_of\_week} column was added to the dataset to represent the weekday on which each observation occurred. This feature allows the models to capture temporal seasonality related to human activity patterns that typically vary across weekdays and weekends. For instance, energy consumption or cooling demand may be systematically higher on weekdays compared to weekends.

\paragraph{Weekend and Weekday Tag}
Building on the day-of-week information, a binary tag distinguishing between weekdays and weekends was introduced. This feature reduces the dimensionality of temporal effects and allows the models to easily account for systematic differences in behaviour between weekdays and weekends.

\paragraph{Month Identifier}
To incorporate longer-term seasonal variations, a \texttt{month} identifier was added. This feature makes it possible to detect monthly or seasonal cycles in the data, such as weather-related patterns or operational schedules that repeat on a monthly basis.

\paragraph{Holiday Combination Feature}
The dataset included two holiday-related variables: \texttt{holiday\_ID}, which was a categorical value ranging from 1 to 22 representing different types of holidays, and \texttt{holiday}, which was a binary value indicating whether a given day was a holiday or not. To enhance the interpretability and usability of these features, a combined feature was created by multiplying \texttt{holiday\_ID} with \texttt{holiday}. This ensured that non-holiday days were represented as zero, while holidays retained their unique identifiers. This transformation simplified model training by consolidating redundant information into a single, more informative feature.

\subsection{Outlier Detection and Removal using the Hampel Identifier Method}
Outliers can significantly bias statistical and machine learning models if not properly addressed. To mitigate this, the Hampel identifier(HI) method was employed for outlier detection. The HI method was chosen because it is a robust statistical technique based on the median and the median absolute deviation (MAD)\cite{hiceemdanQteg}. The method is also robust to heavy tailed data and skewed distributions of raw data. Below are the equations used for the implementation as taken from \cite{hiceemdanQteg}.

Consider the input sequence \(A = [a_1, a_2, \ldots, a_k]\). For each sample \(a_i\), a symmetric sliding window of length \(w = 2n + 1\) centered at \(i\) is defined. Within this window:

\[
m_i = \operatorname{median}(a_{i-n}, \ldots, a_i, \ldots, a_{i+n})
\tag{1}
\]

The median absolute deviation (MAD) is calculated as:

\[
\mathrm{MAD}_i = \operatorname{median}\big(|a_{j} - m_i| : j \in [i-n,\, i+n]\big)
\tag{2}
\]

To estimate the standard deviation, the MAD is scaled using a constant \(\alpha = 0.6745\) (consistent with normal distribution assumptions):

\[
\sigma_i = \frac{\mathrm{MAD}_i}{\alpha}
\tag{3}
\]

An observation is identified as an outlier if it deviates from the local median beyond three times the estimated standard deviation:

\[
|a_i - m_i| > 3\sigma_i
\tag{4}
\]

If an outlier is detected, the original value \(a_i\) is replaced with the local median \(m_i\). This correction preserves the temporal structure of the data while reducing the influence of anomalies. Incorporating HI ensures that erroneous spikes caused by equipment errors, missing sensor calibration, or human errors do not affect model training and forecasting. This HI formulation was shown to improve quality of raw data and reduce time series complexity \cite{hiceemdanQteg}.

\subsubsection{Data Normalization}

To ensure that the features contributed proportionally during model training, all numerical variables in the dataset were normalized, with the exception of the \texttt{datetime} column, which was retained in its original format for temporal referencing and indexing the dataset. Normalization prevents features with larger absolute values from dominating those with smaller ranges, and it improves the convergence behavior of machine learning algorithms.

Several normalization and standardization approaches exist, such as z-score standardization, robust scaling, and Min–Max scaling. In this work, the Min–Max scaling method was selected due to its effectiveness in rescaling features to a fixed range while preserving the original distribution’s shape. The transformation is defined as:

\[
x' = \frac{x - x_{\min}}{x_{\max} - x_{\min}}
\tag{5}
\]

where \(x\) is the original feature value, \(x_{\min}\) and \(x_{\max}\) are the minimum and maximum values of the feature, and \(x'\) is the normalized value rescaled to the interval \([0,1]\).

The Min–Max scaling method was chosen because it is well-suited for neural networks and distance-based models, particularly those relying on gradient descent, as these algorithms perform optimally when features are restricted to a bounded range \cite{featureScaling}. Unlike z-score normalization, which re-centers data around the mean, Min–Max scaling preserves the original relative spacing between values, making it appropriate when proportional differences carry meaning. Furthermore, by rescaling all features to the interval \([0,1]\), it provides a consistent and interpretable representation that simplifies visualization and ensures that all features contribute fairly during training.

By applying Min–Max scaling, the dataset was transformed into a consistent format across all features, thereby improving model training stability and ensuring fair contribution of each feature to the learning process.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{Chapters/images/preprocess}
	\caption{The data preprocessing steps taken to process the data for model training}
	\label{fig:preprocessing}
\end{figure}

The steps taken for the data preprocessing are shown in the fig \ref{fig:preprocessing} 

\section{Evaluation Metrics}
The models were compared using standard error metrics and information criteria that are widely used in forecasting literature. These metrics provide complementary views on model performance in terms of accuracy, error magnitude, and model complexity. The chosen metrics are briefly described below. 

\subsubsection{Mean Absolute Percentage Error (MAPE)} 
MAPE expresses forecast accuracy as a percentage, making it easy to interpret across different scales. Lower values indicate better performance.  
\[
\text{MAPE} = \frac{100}{n}\sum_{t=1}^{n} \left| \frac{Y_t - \hat{Y}_t}{Y_t} \right|
\]

\subsubsection{Mean Squared Error (MSE)} 
MSE penalises larger errors more heavily by squaring them, making it sensitive to outliers.  
\[
\text{MSE} = \frac{1}{n}\sum_{t=1}^{n} (Y_t - \hat{Y}_t)^2
\]

\subsubsection{Root Mean Squared Error (RMSE)} 
RMSE is the square root of MSE and brings the error measure back to the same scale as the original data.  
\[
\text{RMSE} = \sqrt{\frac{1}{n}\sum_{t=1}^{n} (Y_t - \hat{Y}_t)^2}
\]

\subsubsection{Coefficient of Determination ($R^2$)} 
$R^2$ measures how well the forecasts explain the variance in the actual data. Higher values (closer to 1) indicate better fit.  
\[
R^2 = 1 - \frac{\sum_{t=1}^{n} (Y_t - \hat{Y}_t)^2}{\sum_{t=1}^{n} (Y_t - \bar{Y})^2}
\]

\subsubsection{Akaike Information Criterion (AIC)} 
AIC balances model fit and complexity. It penalizes over-parameterized models, with lower values indicating a better trade-off.  
\[
\text{AIC} = 2k - 2\ln(\hat{L})
\]
where $k$ is the number of model parameters and $\hat{L}$ is the maximized likelihood.



\section{Statistical and Machine Learning Models}
\subsection{Exponential Smoothing}

Exponential smoothing has been widely used as a method for STLF due to its low computational needs and fast processing times. The core idea of this method is to produce a forecast from an exponentially weighted average of past observations, giving the largest weight to the most recent data and exponentially decreasing weights to older data \cite{ostertagova2011simple}. This method's functionality has been discussed extensively in section \ref{sec:exponential smoothing}. In this section we will focus on the theoretical fundamentals and the choice of model we used in our research.  

There are multiple forms of ES, each designed to capture different components of a time series data.
\paragraph{Simple Exponential Smoothing(SES)}\label{par:ses}
SES is designed for time series datasets that lack seasonality and trend. The forecast is based solely on the weighted average of past observations. If $\hat{Y}_{t}$  is the value at time t  and $\alpha$ is the smoothing parameter between 0 and 1. The equation for the smoothed value $S_{t}$ would be \ref{eqn:6} as adapted from \cite{ostertagova2011simple}.

\[
\hat{S}_{t+1}  = \alpha Y_t + (1-\alpha)\hat{Y}_t
\tag{6}
\label{eqn:6}
\]
 Though the simplicity of SES is good for very low computational tasks it is not favorable for STLF due to the high level of accuracy required in forecasting and the trend and seasonality present in the data.
 
 \paragraph{Double Exponential Smoothing (DES)} method introduces capturing of trend in the time series data. This is in addition to the already existing level component in SES \ref{par:ses}. The equation of DES as adapted from \cite{nist_double_exp_smoothing} would be:
 \[
  S_t = \alpha Y_t + (1-\alpha)(S_{t-1} + b_{t-1})
  \tag{7}
 \label{eqn:7}
 \] 
 \[
  b_t = \gamma (S_t - S_{t-1}) + (1-\gamma) b_{t-1}
  \tag{8}
 \label{eqn:8}
 \]
 
 where $b_t$ would be the estimated trend or slope of the dataset and $\gamma$ would be the smoothing parameter for the trend  between 0 and 1. The data shows a clear flat trend over the long-term and seasonality every 24 hours with a fast rise and peak demand during midday shown in image \ref{fig:weeklydemand}. This 24 hour seasonality brings us to the third ES model which s the Triple Exponential Smoothing (TES). 
 \begin{figure}[h]
 	\centering
 	\includegraphics[width=0.7\linewidth]{Chapters/images/weekly_demand}
 	\caption{Real electricity demand from Sunday 13th to Saturday 20th of October 2019}
 	\label{fig:weeklydemand}
 \end{figure}
 
 \paragraph{Triple Exponential Smoothing } introduces the equation that takes care of the seasonality component of the data \cite{nist_double_exp_smoothing}. TES inherits equation \ref{eqn:7} and \ref{eqn:8} and introduces equation \ref{eqn:9} for seasonality adapted from \cite{nist_double_exp_smoothing}.
 \[
 I_t = \beta \frac{Y_t}{S_t} + (1-\beta) I_{t-m}  
 \tag{9}
 \label{eqn:9}
 \]
 $I_t$ is the estimated seasonal component and $\beta$ is the seasonality constant that is between 0 and 1. With the combination of equation \ref{eqn:6} , \ref{eqn:8}  and \ref{eqn:9} the overall smoothed value equation would be \ref{eqn:10}. 
 \[
 S_t = \alpha \frac{Y_t}{I_{t-L}} + (1-\alpha)(S_{t-1}+b_{t-1})
 \tag{10}
 \label{eqn:10}
 \]
 
 \paragraph{Damping} is a mechanism used to reduce or dampen the trend in forecasts over long horizons \cite{taylor2003exponential}. This method makes the forecast trend more conservative, preventing it from overshooting the actual data , which is a common issue in ES methods projecting a linear trend indefinitely in the future \cite{taylor2003exponential}. The equation below is for the smoothed value inclusive of the damping factor $\phi$ which is between 0 and 1, adapted from \cite{taylor2003exponential}. With equation \ref{eqn:11.a} being the additive in level and equation \ref{eqn:11.b} being the multiplicative in level.
 \[
 	S_t = \alpha \frac{Y_t}{I_{t-L}} + (1-\alpha)\bigl(S_{t-1} + \phi\, b_{t-1}) 
 \tag{11.a}
 \label{eqn:11.a}
 \]
 
 
 \[
 S_t = \alpha \frac{Y_t}{I_{t-L}} + (1-\alpha)\bigl(S_{t-1} \cdot b_{t-1}^{\,\phi}\bigr)
 \tag{11.b}
 \label{eqn:11.b}
 \]
 

 \subsubsection{Choice of best Exponential Smoothing model}
 The objective of the research is to improve STLF by using Ml and AI methods. ES as a statistical method would  be the benchmark for comparison of the ML models. However because of the different variations of ES an algorithm was  developed to help choose the best performing ES model to be used as the benchmark for the rest of the project. The models performance were compared on their MAPE, MAE, Mean Squared Error(MSE), RMSE and the AIC.
 
 This algorithm would create a model using statsmodel holtwinters \cite{statsmodels_expsmoothing_doc} and test its performance of forecasts on the dataset. Different model's performance would be compared to each other. Image \ref{fig:exponential-smoothing-model-choice} in appendix A shows a flow chart of how the algorithm functions. Table \ref{tab:es_model_selection} shows the different models that were tested to find the best model and their results.
 


\begin{table}[ht]
	\centering
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{lccccccc}
			\hline \\
			\textbf{Model} & \textbf{Trend} & \textbf{Seasonality} & \textbf{Seasonality Period} & \textbf{Damped} & \textbf{MAPE (\%)} & \textbf{MSE (MWh)} & \textbf{AIC}
			 \\
			\hline
			Simple               & None  & None & –  & No  & 13.76\%  & 180.98 & 343990.96 \\
			Double               & Add   & None & –  & No  & 15.14\%  & 172.11 & 327001.68 \\
			Triple\_Add          & Add   & Add  & 24 & No  & 10.56\%  & 125.56 & 277981.02 \\
			Triple\_Mul          & Mul   & Mul  & 24 & No   & 34.48\%  & 408.23 & 272265.85 \\
			Triple\_Add\_Damped  & Add   & Add  & 24 & Yes &  9.99\%  & 120.81 & 277708.98 \\
			Triple\_Mul\_Damped  & Mul   & Mul  & 24 & Yes & 10.01\%  & 119.49 & 272266.18 \\
			\hline
		\end{tabular}%
	}
	\caption{Exponential Smoothing Models chosen for benchmarking and their performance.}
	\label{tab:es_model_selection}
\end{table}

Comparison of performance metrics through the algorithm in figure \ref{fig:exponential-smoothing-model-choice} was the Triple Multiplicative Damped algorithm with a seasonality period of 24 data points. Since the dataset is sampled hourly the seasonality was set to 24 hours. The MAPE and MSE are very close to each other with a difference of about 0.01 each. However the AIC value for  $Triple\_Mul\_Damped$ is lower than the one for $Triple\_Add\_Damped$, this showing a better model fit for  $Triple\_Mul\_Damped$. The final choice for the ES model was  $Triple\_Mul\_Damped$ and it served as a benchmark for testing performance of other models used in the experiment.
\subsubsection{Implementation of the Triple Multiplicative Damped ES model}



\subsection{Deep Belief Network}
 
 A DBN is a probabilistic generative model composed of multiple layers of stochastic, latent variables \cite{zhang2017deep}. It is constructed by stacking multiple layers of RBMs on top of each other \cite{zhang2016short}. This model benefits from its capabilities of limiting the occurrence of the local minima by pre-training RBMs using unsupervised training to adjust weights and parameters to ensure an enhanced performance in actual prediction use cases.
 
\subsubsection{Restricted Boltzmann Machine (RBM)}

A Restricted Boltzmann Machine (RBM) is a two-layer probabilistic generative model designed to learn the underlying probability distribution of input data. RBMs are widely used as building blocks for constructing DBNs \cite{dong2021short}. The architecture consists of a \textit{visible layer}, which receives the observed data, and a \textit{hidden layer}, which captures latent features and higher-order correlations in the data. Learning in RBMs is unsupervised: the model attempts to represent the structure of the input data by adjusting its parameters weights and biases so as to maximize the likelihood of the training samples \cite{zhang2017deep}.

An RBM is defined by a weight matrix that connects each visible unit to each hidden unit in a bipartite manner, together with bias vectors for both layers. No intra-layer connections are permitted, which simplifies inference and training. The structure is shown in figure \ref{fig:singlerbm}, adapted from Zhang et al. \cite{zhang2017deep}.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\linewidth]{Chapters/images/singleRBM}
	\caption{Illustration of an RBM with visible and hidden layers, including weights and biases}
	\label{fig:singlerbm}
\end{figure}

\paragraph{Energy-Based Formulation: } 
An RBM is an energy-based model, meaning it assigns a scalar energy value to each configuration of visible and hidden units. Configurations with lower energy are more likely under the model. The energy function is given by \cite{kong2019improved, zhang2016short}:

\[
E(v,h;\theta) = -\sum_i a_i v_i - \sum_j b_j h_j - \sum_{i,j} v_i W_{ij} h_j
\tag{12}
\label{eqn:12}
\]

where
\begin{itemize}
	\item $v_i$: the state of visible unit $i$,
	\item $h_j$: the state of hidden unit $j$,
	\item $a_i$: the bias associated with visible unit $i$,
	\item $b_j$: the bias associated with hidden unit $j$,
	\item $W_{ij}$: the weight between visible unit $i$ and hidden unit $j$,
	\item $\theta = \{W, a, b\}$: the model parameters.
\end{itemize}

\paragraph{Probability Distribution: } 
Using the energy function, the joint probability of a visible–hidden configuration is defined by the Boltzmann distribution \cite{DBN_GeeksforGeeks}:

\[
P(v,h) = \frac{e^{-E(v,h)}}{Z}
\tag{13}
\label{eqn:13}
\]

where $Z$ is the \textit{partition function}, given by summing over all possible visible and hidden states:
\[
Z = \sum_{v,h} e^{-E(v,h)}
\]

The probability of a visible vector $v$ is obtained by marginalizing out the hidden layer:
\[
P(v) = \frac{1}{Z} \sum_{h} e^{-E(v,h)}
\]

\paragraph{Training RBMs:} 
RBMs are typically trained using the \textit{Contrastive Divergence} (CD) algorithm. Training consists of two phases:

\begin{enumerate}
	\item \textbf{Positive phase:} a visible vector from the data activates the hidden layer, and correlations $\langle v_i h_j \rangle_{\text{data}}$ are computed.
	\item \textbf{Negative phase:} the hidden units are used to reconstruct the visible layer, producing a reconstructed vector. From this, correlations $\langle v_i h_j \rangle_{\text{recon}}$ are obtained.
\end{enumerate}

The difference between the two phases provides the learning signal for updating weights:
\[
\Delta W_{ij} = \eta \Big( \langle v_i h_j \rangle_{\text{data}} - \langle v_i h_j \rangle_{\text{recon}} \Big)
\tag{14}
\label{eqn:14}
\]
where $\eta$ is the learning rate. In this way, the RBM iteratively learns to reduce the gap between the distribution of the training data and the distribution it models. The feed-forward (data-to-hidden) and feed-backward (hidden-to-reconstruction) passes, together with weight updates, constitute the CD training loop \cite{RBM_GeeksforGeeks}.

\paragraph{RBMs are stacked to create a DBN} When 1 or more RBMs are stacked together they create a DBN. This DBN has the advantage of pre-trained RBMs that have adjusted their weightings to minimize error in the training phase. Stacking of RBMs is as shown in the figure \ref{fig:correctrbm}.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{Chapters/images/CORRECT_RBM}
	\caption{An illustration of stacked RBMs making a DBN}
	\label{fig:correctrbm}
\end{figure} 
This illustration highlights how the hidden layer of the first RBM is the visible layer of RBM 2. During pretraining each RBM is trained separately RBM1 will receive the original data and perform CD on RBM1, the recreated output on the hidden layer 1(HD1) becomes the input of RBM2 through the visible layer 2(V2). RBM2 will go through CD and continues the loop until the full RBM has been trained.

\subsection{Implementation of DBN architecture for STLF}
The proposed DBN designed for the STLF task, leverages its hierarchical feature extraction capabilities to model complex temporal and non linear dependencies present in the time series data.

The DBN was implemented using \textit{tensorflow.keras.callbacks} for fitting, evaluating and prediction functionality of the model. The DBN also uses \textit{tensorflow.keras.layers} for creating the different RBM layers in the model. Scikit-learn was also used for data scaling and evaluating performance using features such as the \textit{MinMaxScaler} and \textit{mean\_absolute\_percentage\_error}. 
\subsubsection{Input Feature Engineering}
The original dataset went through its initial feature engineering as explained in section \ref{sec:datapreprocessing}, however further feature engineering is performed to enhance performance.

\begin{enumerate}
	\item \textbf{Lagged Load Values : } This is essential for capturing time series auto correlation, to do so the network uses lagged values of nat\_demand at $\tau$ = [1,2,3,7,24,168] hours . These lags will enable capturing past demand for 1-3 hours, 24 hours and 168 hours which is a week. The lags are important for capturing seasonality and aligns with the seasonality benchmark in the ES implementation.
	\item \textbf{Cyclical Encoding : } To avoid discontinuities and ensure the network learns smooth transition of time eg from 11PM to 12 AM , cyclical encoding is applied to hour, day of week and month. With cyclical encoding the times 11PM and 12AM are represented as being close to each. This is performed by using sine and cosine transformation to the dataset columns associated.
	\item \textbf{Rolling Statistics : } Mean and standard deviation of nat\_demand over 7 and 24-hour windows are included to capture recent trend and volatility.
\end{enumerate}
All missing values resulting from lag and rolling window operations were handled through forward and backward filling, followed by complete case removal to ensure data integrity. The final feature set comprised approximately 20-25 input variables depending on the available data columns.
\subsubsection{DBN Structure}
The DBN structure comprises a stacking of 3 RBMs, forming a deep architecture representation. Table \ref{tab:dbn_architecture} shows the representation of each layer.
\begin{table}[h]
	\centering
	
	
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{lccc}
		\hline \\
		\textbf{Layer Type} & \textbf{Units ($\boldsymbol{n}_{\mathbf{h}}$)} & \textbf{Activation (RBM Pre-training)} & \textbf{Activation (Fine-Tuning)} \\
		\hline
		\\
		RBM 1 (H1) & 256 & Sigmoid ($\sigma$) & ReLU \\
	
		RBM 2 (H2) & 128 & Sigmoid ($\sigma$) & ReLU \\
	
		RBM 3 (H3) & 64 & Sigmoid ($\sigma$) & ReLU \\
	
		Fine-Tuning Layer & 32 & N/A & ReLU \\
	
		Output Layer & 1 & - & Linear (None) \\
	\hline
	\end{tabular}
}
	\caption{DBN Layer configuration}
	\label{tab:dbn_architecture}
\end{table}

The architecture had 3 RBMs setup with 256, 128 and 64 units respectively. Each of these layers were trained using CD , before being stacked and initialized for the deep network. The final layer added a dense layer of 32 ReLU units for fine=tuning and a linear regression output layer for predicting continuous load values. The ReLu activation function is chosen due to its ability to mitigate to the disappearing gradient problem \cite{bibid}.\\
 The fine tuning layer acts as the combiner of RBM-initialized layers, putting them together before the output layer. This design implementation was chosen to allow the network to learn task specific transformations on top of the general features learned during unsupervised learning.\\ The final output layer is a single dense linear unit without an activation function, producing a continuous regression output representing the forecasted electricity demand. This type of output is appropriate for regression tasks as it allows the network to predict values across the full range of the target value without constraints.
\textbf{ADD AN IMAGE OF THE DBN}

\subsection{Training Procedure}
 DBN training is split into two sections, unsupervised learning for the RBMs and supervised learning for the stacked RBMs. These procedures will effectively initialize a deep forward netowrk to a good starting point.
 \subsubsection{Pre-training (Unsupervised)}Each of the RBMs are trained sequentially using the input data X\_train is an unsupervised manner to learn a robust and hierarchical representation of the input features. The CD algorithmn explained in \ref{label} is what is used to train each RBM, approximating the gradient using the error equation \ref{}. A fixed momentum term of 0.9 is set to accelerate convergence and dampen oscillation.\\ The learning rate was implemented during the pretraining, starting at 0.01 for the first layer and decaying by a factor or 0.8 for each subsequent RBM layer. This decaying factor is to counter the increasing abstraction in higher layer which will require the updates of the layers to be more conservative. Each RBM is trained for 25 epochs, this is because there was a negligible change in the final prediction with increased epochs.
 
 \subsubsection{Fine-Tuning (Supervised)} Following the supervised pre-training, the network was unrolled nto a standard feed-forward neural network and fine tuned using supervised learning. The learned RBM weights and biases from the pre-training are transferred to initialize the corresponding dense layers in the supervised network. This initialization provides the network with meaningful feature representation. After the transfer the network will learn through supervised learning using standard back-propagation method which will train the network end-to-end.
 The Adam optimizer is chosen with a base learning rate of 0.001. Adam is preferred over standard SGD for deep learning due to its adaptive learning rates for individual parameters, leading to faster and more stable convergence. The network is then compiled using MSE as its loss function, which is appropriate for regression tasks and is minimized during training.
 
 \subsubsection{Regularization Strategies}
 Multiple regularization strategies were employed to prevent overfitting and improve generalization.
 
 \begin{itemize}
 	\item \textbf{L2 Weight Decay} : Applied to the kernel weights of all dense layers with a factor of 0.001 to prevent overfitting by penalizing large weights.
 	\item \textbf{Dropout} : A dropout rate of 0.2 is applied between the hidden layers, and a lower rate (0.1) is applied to the input layer and the final fine-tuning layer to prevent over-reliance on specific neurons.
 	\item \textbf{Early Stopping} : Training terminates if the validation loss) does not improve for 15 consecutive epochs. The best weights corresponding to the lowest validation loss are restored.
 	\item \textbf{Reduce LR On Plateau} : The learning rate is dynamically halved (factor=0.5) if the validation loss plateaus for 8 epochs, ensuring the model can escape local minima.
 \end{itemize}
 
 \textbf{ ADD AN IMAGE OF THE COMPLETE STEP BY STEP OF THE INITIALIZATION AND TRAINING OF THE DBN}
 
 
 The DBN was evaluated using three complementary metrics to capture the different aspects of forecasting accuracy. MAPE, MAE and RMSE were used to evaluate and compare the DBN with the other models. These evaluations were performed on inverse transformed predictions to ensure the validation occurred in the original load scale rather than the normalized space used for training. Performance was also assessed separately on both training and test sets to monitor potential overfitting and evaluate generalization capability.
 
 
 
 \subsection{Long Short Term Memory Methodology}
 
 LSTM is a specialized type of RNN that is particularly effective for time series data prediction \cite{rafi2021short}
 . As an improved version of traditional RNN, the LSTM networks are designed to overcome long-term dependency issues such as vanishing and exploding gradients that can occur when processing long data sequences \cite{boopathy2024deep}. The LSTM was chosen for its effectiveness is overcoming long term dependency in this task of STLF. The data used for this task has long sequences. Using an RNN for this task would easily introduce the vanishing gradient problem as the model tries to remember long term dependencies of the data.
 
 The ability of LSTM to be versatile and also potentially producing more accurate solutions that statistical methods made it very suitable as a contender in this research. Since our data is time series data and any prediction thereof should consider past data points to make an accurate prediction made this model a top choice for evaluation.
 
\subsubsection{LSTM Theoretical Background}
 
\paragraph{AN RNN Background} is essential to understand how an LSTM model functions. An RNN is a model that utilizes past sets of information to make a prediction of the present. They achieve this feat by using a feedback loop. The RNN tracks context or previous data on a hidden state at each time step \cite{stryker_ibm_rnn}. This hidden state then works as the memory of the system. 
Imagine \textit{A} is a single unit of the RNN receiving input \textit{$X_t$} , \textit{A} will have a  hidden state \textit{$H_t$} that will store information about the previous input $X_{t-1}$ and it will output \textit{$Y_t$}. Image \ref{fig:rnnsingleunit} adapted from \cite{colah2015understanding} shows how the single unit looks like.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.1\linewidth]{Chapters/images/rnn_singleunit}
	\caption{A single unit of a recurrent neural network}
	\label{fig:rnnsingleunit}
\end{figure}
If the single unit in figure \ref{fig:rnnsingleunit} is unrolled we will end up with a simple RNN as shown in \ref{fig:unrolledrnn} as adapted from \cite{colah2015understanding}.


\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{Chapters/images/unrolled_rnn.jpeg}
	\caption{An unrolled rnn}
	\label{fig:unrolledrnn}
\end{figure}

An LSTM uses a similar mechanism  to remember past data. It introduces the concept of gates which act as a control mechanism for the what data to keep and discard as we process information in the LSTM. The LSTM has four main components the cell state , forget gate , input gate and output gate. These control the full mechanism of this neural network.

\subsubsection{Cell State}
The cell state is a block of information that propagates all the units of the LSTM. This unit contains the data from previous states that will be used as context in future data cells. \\ 

\begin{figure}[h]
	\centering
	\includegraphics[width=1\linewidth]{Chapters/images/cellstate}
	\caption{Cell state propagating through different units of the LSTM carrying data from previous states to future units}
	\label{fig:cellstate}
\end{figure} 

 The image \ref{fig:cellstate} above shows the cell state \textit{$C_{t}$} propagating through the basic unit of an LSTM \textit{$A_t$}. In each of these units through an additive and multiplicative process data is added and removed from the cell state. 
 \subsubsection{Forget gate}
 
The cell state contains previous information however there needs to be a way to determine what information is important. The forget gate decides what information to discard from the previous cell state  \textit{$C_{t-1}$} \cite{zhu2025novel}. During back-propagation the forget gate plays a crucial role. If it learns that certain information is important and should be kept for long, the forget gates activation function will be close to 1 and 0 if the information is not very important \cite{zhu2025novel}. Equation \ref{eqn:15}  below adapted from \cite{colah2015understanding} shows how the forget gate works.

\[
f_t = \sigma \Big( W_f \cdot [h_{t-1}, x_t] + b_f \Big)
\tag{15}
\label{eqn:15}
\]

\begin{itemize}
	\item $f_t$: Forget gate activation vector at time step $t$ (values between 0 and 1).
	\item $\sigma$: Sigmoid activation function.
	\item $W_f$: Weight matrix for the forget gate.
	\item $[h_{t-1}, x_t]$: Concatenation of the previous hidden state $h_{t-1}$ and the current input $x_t$.
	\item $b_f$: Bias vector for the forget gate.
\end{itemize}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{"Chapters/images/LSTM input gate"}
	\caption{Forget gate of an LSTM}
	\label{fig:forgetgate}
\end{figure}
Figure \ref{fig:forgetgate} adapted from \cite{colah2015understanding} shows how the hidden state $h_{t-1}$ and input $x_t$ concatenate together. The concatenated hidden state and input are multiplied with a weight $W_f$ associated with the input.This sigmoid function also has a bias input vector $b_f$ that is added to the weighted hidden state and input .  The two are passed through a sigmoid function using the ReLU activation function giving a number between 0 and 1 as the output. Finally the function $f_t$ is multiplied with $c_{t-1}$ to determine if we add or subtract from the cell state.

\[
C_{t-1}*f_t = 0   ..... \text{    if} f_t = 0 \text{           (forget everything)}
\tag{16.a}
\label{eqn:16.a}
\]

\[
C_{t-1}*f_t = 1  ..... \text{  if} f_t = 1 \text{            (forget nothing)}
\tag{16.b}
\label{eqn:16.b}
\]
 Equation \ref{eqn:16.a} and \ref{eqn:16.b} adapted from \cite{stryker_ibm_rnn} shows how the forget gate will be applied to the cell state through the multiplicative process.
 
 
 \subsubsection{Input Gate}
 The input gate determines what new information from the current input and previous hidden state should be stored in the current cell state \cite{rafi2021short}. 
 The input gate quantifies the importance of new data carried in the input \cite{stryker_ibm_rnn}. The input layer is split into two parts, the output of the input gate $i_t$ and a candidate cell state $\tilde{C_t}$ used to update the global cell state. $\tilde{C_t}$ allows retaining of important information and effectively updating the global cell state \cite{zhu2025novel}.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{Chapters/images/forget_inputgates}
	\caption{An LSTM unit with the forget and input gate }
	\label{fig:forgetinputgates}
\end{figure}

Figure \ref{fig:forgetinputgates} shows how the forget and input gates. Below are the equations that determine the functionality of the input gate. % Input gate equation
\[
i_t = \sigma \Big( W_i \cdot [h_{t-1}, x_t] + b_i \Big)
\tag{18}
\label{eqn:inputgate}
\]

% Candidate cell state
\[
\tilde{C}_t = \tanh \Big( W_c \cdot [h_{t-1}, x_t] + b_c \Big)
\tag{19}
\label{eqn:candidatecell}
\]

% Cell state update
\[
C_t = f_t \odot C_{t-1} + i_t \odot \tilde{C}_t
\tag{20}
\label{eqn:cellupdate}
\]

\begin{itemize}
	\item $i_t$: Input gate output at time step $t$.
	\item $\sigma$: Sigmoid activation function.
	\item $W_i, W_c$: Weight matrices for the input gate and candidate cell state.

	\item $b_i, b_c$: Bias vectors for the input gate and candidate cell state.
	\item $\tilde{C}_t$: Candidate cell state (potential new memory).
	\item $\tanh$: Hyperbolic tangent activation function.
	\item $C_t$: Updated cell state at time step $t$.
	\item $f_t$: Forget gate activation vector at time step $t$.
	\item $C_{t-1}$: Previous cell state.
	\item $\odot$: Element-wise product.
\end{itemize}

As shown in figure \ref{fig:forgetinputgates} the candidate cell state and the input output gate are combined through an element wise multiplication. The global cell state is also updated by using an additive operation of the forget gate output and the output of the multiplication in the input gate.
 \subsubsection{Output Gate}
The output gate determines what information from the cell state should be passed onto the hidden state \cite{zhu2025novel}. The hidden state acts as the output of the unit of processing and will also be used in the following units of processing.
 \begin{figure}[h]
 	\centering
 	\includegraphics[width=0.5\linewidth]{Chapters/images/forget_input_output_gates1}
 	\caption{forget input and output gates together}
 	\label{fig:forgetinputoutputgates1}
 \end{figure}
 Figure \ref{fig:forgetinputoutputgates1} shows the complete unit of processing with the output gate. The hidden state takes a sigmoid processed concatenated $h_t{t-1}$ and $x_t$ with a tanh processed $C_t$ the output will be through a multiplicative output. 
 % Output gate equation
 \[
 o_t = \sigma \Big( W_o \cdot [h_{t-1}, x_t] + b_o \Big)
 \tag{21}
 \label{eqn:outputgate}
 \]
 
 % Hidden state update
 \[
 h_t = o_t \odot \tanh(C_t)
 \tag{22}
 \label{eqn:hiddenstate}
 \]
 \begin{itemize}
 	\item $o_t$: Output gate activation vector at time step $t$.
 	\item $\sigma$: Sigmoid activation function.
 	\item $W_o$: Weight matrix for the output gate.
 
 	\item $b_o$: Bias vector for the output gate.
 	\item $h_t$: Hidden state at time step $t$ (output of the LSTM block).
 	\item $C_t$: Updated cell state at time step $t$.
 	\item $\tanh$: Hyperbolic tangent activation function.
 	\item $\odot$: Element-wise product.
 \end{itemize}
  Equation \ref{eqn:outputgate}  shows the combination for the output and \ref{eqn:hiddenstate} shows the output of the LSTM unit.
  
  
 \begin{figure}[h]
 	\centering
 	\includegraphics[width=0.7\linewidth]{"Chapters/images/full lstm"}
 	\caption{full lstm}
 	\label{fig:full-lstm}
 \end{figure}
 